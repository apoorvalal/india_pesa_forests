{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_loc = 'C:/Users/nikhi/Downloads/chromedriver'\n",
    "driver = webdriver.Chrome(chrome_driver_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('C:/Users/nikhi/Dropbox/Jharkhand Minerals/Lessee Profile Links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dmo Name</th>\n",
       "      <th>Lessee Name</th>\n",
       "      <th>Mines Name</th>\n",
       "      <th>ML/RML</th>\n",
       "      <th>Lessee Code</th>\n",
       "      <th>Mineral</th>\n",
       "      <th>detail_link</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GARHWA</td>\n",
       "      <td>BELCHAMPA SAND MINIG PROP AMIT GUPTA</td>\n",
       "      <td>BELCHAMPA SAND MINIG PROJECT</td>\n",
       "      <td>AUCTION</td>\n",
       "      <td>412141101</td>\n",
       "      <td>SAND</td>\n",
       "      <td>https://portal.jharkhandminerals.gov.in/portal...</td>\n",
       "      <td>Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>LOHARDAGA</td>\n",
       "      <td>JANKALYAN VIKASH SAMITI</td>\n",
       "      <td>BHAKSO SAND GHAT</td>\n",
       "      <td>AUCTION</td>\n",
       "      <td>516122601</td>\n",
       "      <td>SAND</td>\n",
       "      <td>https://portal.jharkhandminerals.gov.in/portal...</td>\n",
       "      <td>Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>PALAMU</td>\n",
       "      <td>MS HINDALCO INDUSTRIES LTD</td>\n",
       "      <td>MS HINDALCO INDUSTRIES LTD</td>\n",
       "      <td>AUCTION</td>\n",
       "      <td>411310001</td>\n",
       "      <td>COAL</td>\n",
       "      <td>https://portal.jharkhandminerals.gov.in/portal...</td>\n",
       "      <td>Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>PALAMU</td>\n",
       "      <td>MS JULANGA BALU GHAT PRO ANUPAM KUMAR SINGH</td>\n",
       "      <td>MS JULANGA BALU GHAT PRO ANUPAM KUMAR SINGH</td>\n",
       "      <td>AUCTION</td>\n",
       "      <td>411153501</td>\n",
       "      <td>SAND</td>\n",
       "      <td>https://portal.jharkhandminerals.gov.in/portal...</td>\n",
       "      <td>Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>SARAIKELA KHARSAWAN</td>\n",
       "      <td>NIKHIL AGARWAL</td>\n",
       "      <td>NIKHIL AGARWAL</td>\n",
       "      <td>AUCTION</td>\n",
       "      <td>103516301</td>\n",
       "      <td>SAND</td>\n",
       "      <td>https://portal.jharkhandminerals.gov.in/portal...</td>\n",
       "      <td>Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>RANCHI</td>\n",
       "      <td>SURJEET KUMAR SINGH</td>\n",
       "      <td>SURJEET KUMAR SINGH</td>\n",
       "      <td>AUCTION</td>\n",
       "      <td>514517401</td>\n",
       "      <td>SAND</td>\n",
       "      <td>https://portal.jharkhandminerals.gov.in/portal...</td>\n",
       "      <td>Non-Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>HAZARIBAGH</td>\n",
       "      <td>TOKISUD NORTH COAL MINE</td>\n",
       "      <td>TOKISUD NORTH COAL MINE</td>\n",
       "      <td>AUCTION</td>\n",
       "      <td>307178501</td>\n",
       "      <td>COAL</td>\n",
       "      <td>https://portal.jharkhandminerals.gov.in/portal...</td>\n",
       "      <td>Non-Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>KHUNTI</td>\n",
       "      <td>UNITH KUMAR KASHYAP</td>\n",
       "      <td>TORPA BARKULI</td>\n",
       "      <td>AUCTION</td>\n",
       "      <td>515539101</td>\n",
       "      <td>SAND</td>\n",
       "      <td>https://portal.jharkhandminerals.gov.in/portal...</td>\n",
       "      <td>Non-Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>KHUNTI</td>\n",
       "      <td>UNITH KUMAR KASHYAP</td>\n",
       "      <td>FUDI</td>\n",
       "      <td>AUCTION</td>\n",
       "      <td>515539102</td>\n",
       "      <td>SAND</td>\n",
       "      <td>https://portal.jharkhandminerals.gov.in/portal...</td>\n",
       "      <td>Non-Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>KHUNTI</td>\n",
       "      <td>UNITH KUMAR KASHYAP</td>\n",
       "      <td>KORAKEL SAND BALUGHAT</td>\n",
       "      <td>AUCTION</td>\n",
       "      <td>515539103</td>\n",
       "      <td>SAND</td>\n",
       "      <td>https://portal.jharkhandminerals.gov.in/portal...</td>\n",
       "      <td>Non-Working</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dmo Name                                  Lessee Name  \\\n",
       "36                 GARHWA         BELCHAMPA SAND MINIG PROP AMIT GUPTA   \n",
       "84              LOHARDAGA                      JANKALYAN VIKASH SAMITI   \n",
       "332                PALAMU                   MS HINDALCO INDUSTRIES LTD   \n",
       "369                PALAMU  MS JULANGA BALU GHAT PRO ANUPAM KUMAR SINGH   \n",
       "583   SARAIKELA KHARSAWAN                               NIKHIL AGARWAL   \n",
       "...                   ...                                          ...   \n",
       "3750               RANCHI                          SURJEET KUMAR SINGH   \n",
       "3774           HAZARIBAGH                      TOKISUD NORTH COAL MINE   \n",
       "3793               KHUNTI                          UNITH KUMAR KASHYAP   \n",
       "3794               KHUNTI                          UNITH KUMAR KASHYAP   \n",
       "3795               KHUNTI                          UNITH KUMAR KASHYAP   \n",
       "\n",
       "                                       Mines Name   ML/RML  Lessee Code  \\\n",
       "36                   BELCHAMPA SAND MINIG PROJECT  AUCTION    412141101   \n",
       "84                               BHAKSO SAND GHAT  AUCTION    516122601   \n",
       "332                    MS HINDALCO INDUSTRIES LTD  AUCTION    411310001   \n",
       "369   MS JULANGA BALU GHAT PRO ANUPAM KUMAR SINGH  AUCTION    411153501   \n",
       "583                                NIKHIL AGARWAL  AUCTION    103516301   \n",
       "...                                           ...      ...          ...   \n",
       "3750                          SURJEET KUMAR SINGH  AUCTION    514517401   \n",
       "3774                      TOKISUD NORTH COAL MINE  AUCTION    307178501   \n",
       "3793                                TORPA BARKULI  AUCTION    515539101   \n",
       "3794                                         FUDI  AUCTION    515539102   \n",
       "3795                        KORAKEL SAND BALUGHAT  AUCTION    515539103   \n",
       "\n",
       "     Mineral                                        detail_link       status  \n",
       "36      SAND  https://portal.jharkhandminerals.gov.in/portal...      Working  \n",
       "84      SAND  https://portal.jharkhandminerals.gov.in/portal...      Working  \n",
       "332     COAL  https://portal.jharkhandminerals.gov.in/portal...      Working  \n",
       "369     SAND  https://portal.jharkhandminerals.gov.in/portal...      Working  \n",
       "583     SAND  https://portal.jharkhandminerals.gov.in/portal...      Working  \n",
       "...      ...                                                ...          ...  \n",
       "3750    SAND  https://portal.jharkhandminerals.gov.in/portal...  Non-Working  \n",
       "3774    COAL  https://portal.jharkhandminerals.gov.in/portal...  Non-Working  \n",
       "3793    SAND  https://portal.jharkhandminerals.gov.in/portal...  Non-Working  \n",
       "3794    SAND  https://portal.jharkhandminerals.gov.in/portal...  Non-Working  \n",
       "3795    SAND  https://portal.jharkhandminerals.gov.in/portal...  Non-Working  \n",
       "\n",
       "[95 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[links['ML/RML']=='AUCTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RML - rptAccordian_ctl00_tblView\n",
    "#AUCTION - rptAccordian_ctl00_tblView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 36\n",
    "link = links['detail_link'][i]\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df):\n",
    "    cols = list(df.columns)\n",
    "    for i in range(len(cols)):\n",
    "        c = cols[i]\n",
    "        try :\n",
    "            temp = int(c[c.rfind('.')+1:])\n",
    "            cols[i] = c[:c.rfind('.')]\n",
    "        except:\n",
    "            continue\n",
    "    return pd.DataFrame([cols]+df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LESSEE DETAILS\n",
    "def get_lessee_details(link):\n",
    "    linkId = 'LesseeProfile'\n",
    "    tableId = 'grdLProfile'\n",
    "    r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    pre = ''\n",
    "    details = {}\n",
    "    try:\n",
    "        df = pd.read_html(str(soup.find(\"table\",{\"id\":tableId})))[1]\n",
    "    except:\n",
    "        return details\n",
    "    for l in df.values:\n",
    "        if len(set([x for x in l if x==x])) == 1:\n",
    "            pre = l[0] +' '\n",
    "            continue\n",
    "        i=1\n",
    "        last_detail = 'abcdef'\n",
    "        while i<len(l):\n",
    "            if l[i-1]==last_detail:\n",
    "                i+=1\n",
    "                continue\n",
    "            details.update({pre+str(l[i-1]):l[i]})\n",
    "            last_detail = l[i]\n",
    "            if l[i] == 'Contact Person Name':\n",
    "                break\n",
    "            i+=2\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEASE INFO\n",
    "def get_lease_info(link,ml=1):\n",
    "    linkId = 'LesseeInfo'\n",
    "    tableId = 'grdLeaseInfo'\n",
    "    pre = ''\n",
    "    details = {}\n",
    "    r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    try:\n",
    "        df = pd.read_html(str(soup.find(\"div\",{\"class\":\"viewTable\"}).find({\"table\"})))[1]\n",
    "    except:\n",
    "        return details\n",
    "    for l in df.values:\n",
    "        if len(set([x for x in l if x==x])) == 1:\n",
    "            pre = l[0] +' '\n",
    "            continue\n",
    "        i=1\n",
    "        if l[0] == 'Non Forest Area (HA)':\n",
    "            pre = pre+l[0]+' '\n",
    "            i=2\n",
    "        last_detail = 'abcdef'\n",
    "        while i<len(l):\n",
    "            if l[i-1]==last_detail:\n",
    "                i+=1\n",
    "                continue\n",
    "            details.update({pre+str(l[i-1]):l[i]})\n",
    "            last_detail = l[i]\n",
    "            i+=2\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOREST CLEARANCE\n",
    "def get_forest_clearance(link,ml=1):\n",
    "    linkId = 'ForestClearance'\n",
    "    tableId = 'grdForClear'\n",
    "    pre = ''\n",
    "    details = {}\n",
    "    r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    try:\n",
    "        df = pd.read_html(str(soup.find(\"table\",{\"id\":tableId})))[ml]\n",
    "    except:\n",
    "        return details\n",
    "    df = df['Forest Clearance']\n",
    "    df = remove_columns(df)\n",
    "    for l in df.values:\n",
    "        if len(set([x for x in l if x==x])) == 1:\n",
    "            pre = l[0] +' '\n",
    "            continue\n",
    "        i=1\n",
    "        if l[0] == 'Stage 1 Clearance':\n",
    "            pre = pre+l[0]+' '\n",
    "            i=3\n",
    "        elif l[0] == 'Stage 2 Clearance':\n",
    "            pre = 'Non-Forest Land Details '+l[0]+' '\n",
    "            i=3        \n",
    "        last_detail = 'abcdef'\n",
    "        while i<len(l):\n",
    "            if l[i-1]==last_detail:\n",
    "                i+=1\n",
    "                continue\n",
    "            details.update({pre+str(l[i-1]):l[i]})\n",
    "            last_detail = l[i]\n",
    "            i+=2\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENVIRONMENT CLEARANCE\n",
    "def get_env_clearance(link,ml=1):\n",
    "    linkId = 'EnvClearance'\n",
    "    tableId = 'grdEnv'\n",
    "    if not ml:\n",
    "        tableId = 'rptAccordian_ctl00_tblView'\n",
    "    r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    details = {}\n",
    "    try:\n",
    "        df = pd.read_html(str(soup.find(\"table\",{\"id\":tableId})))[0]\n",
    "    except:\n",
    "        return details\n",
    "    for i in df.index:\n",
    "        for c in df.columns:\n",
    "            details.update({c+' '+str(i+1):df[c][i]})\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POLLUTION CLEARANCE\n",
    "def get_pol_clearance(link):\n",
    "    linkId = 'PCBClearance'\n",
    "    tableId = 'grdOspcbML'\n",
    "    pre = ''\n",
    "    details = {}\n",
    "    r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    try:\n",
    "        dfs = pd.read_html(str(soup.find(\"table\",{\"id\":tableId})))\n",
    "    except:\n",
    "        return details\n",
    "    df = remove_columns(df)\n",
    "    for j in range(1,len(dfs)):\n",
    "        df = remove_columns(dfs[j])\n",
    "        for l in df.values:\n",
    "            if len(set([x for x in l if x==x])) == 1:\n",
    "                pre = l[0] +' ' + str(j)+' '\n",
    "                continue\n",
    "            i=1\n",
    "            last_detail = 'abcdef'\n",
    "            while i<len(l):\n",
    "                if l[i-1]==last_detail:\n",
    "                    i+=1\n",
    "                    continue\n",
    "                details.update({pre+str(l[i-1]):l[i]})\n",
    "                last_detail = l[i]\n",
    "                i+=2\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SURVEY\n",
    "def get_survey_details(link):\n",
    "    linkId = 'Survey'\n",
    "    tableId = 'grdSurveyML'\n",
    "    pre = ''\n",
    "    details = {}\n",
    "    r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    try:\n",
    "        df = pd.read_html(str(soup.find(\"table\",{\"id\":tableId})))[1]\n",
    "    except:\n",
    "        return details\n",
    "    df = remove_columns(df)\n",
    "    for l in df.values:\n",
    "        if len(set([x for x in l if x==x])) == 1:\n",
    "            pre = l[0] +' '\n",
    "            continue\n",
    "        i=1\n",
    "        last_detail = 'abcdef'\n",
    "        while i<len(l):\n",
    "            if l[i-1]==last_detail:\n",
    "                i+=1\n",
    "                continue\n",
    "            details.update({pre+str(l[i-1]):l[i]})\n",
    "            last_detail = l[i]\n",
    "            i+=2\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MINING PLAN\n",
    "def get_mining_plan_details(link):\n",
    "    linkId = 'MiningPlan'\n",
    "    tableId = 'tbML'\n",
    "    pre = 'Mining Plan '\n",
    "    details = {}\n",
    "    r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    try:\n",
    "        df = pd.read_html(str(soup.find(\"table\",{\"id\":tableId})))[0].iloc[1:5,1:]\n",
    "    except:\n",
    "        return details\n",
    "    for l in df.values:\n",
    "        if len(set([x for x in l if x==x])) == 1:\n",
    "            pre = l[0] +' '\n",
    "            continue\n",
    "        i=1\n",
    "        last_detail = 'abcdef'\n",
    "        while i<len(l):\n",
    "            if l[i-1]==last_detail:\n",
    "                i+=1\n",
    "                continue\n",
    "            if pre in l[i-1]:\n",
    "                details.update({l[i-1]:l[i]})\n",
    "            else:\n",
    "                details.update({pre+str(l[i-1]):l[i]})\n",
    "            last_detail = l[i]\n",
    "            i+=2\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MINING PLAN 2\n",
    "def get_mining_plan_grid_details(link):\n",
    "    linkId = 'MiningPlan'\n",
    "    tableId = 'grdMiningPlan'\n",
    "    r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    details = {}\n",
    "    try:\n",
    "        df = pd.read_html(str(soup.find(\"table\",{\"id\":tableId})))[0]\n",
    "    except:\n",
    "        return details\n",
    "    for i in df.index:\n",
    "        for c in df.columns:\n",
    "            details.update({c+' '+str(i+1):df[c][i]})\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRANT/EXECUTION\n",
    "def get_grant_details(link):\n",
    "    linkId = 'Grant'\n",
    "    tableId = 'grLGrant'\n",
    "    pre = ''\n",
    "    details = {}\n",
    "    r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    try:\n",
    "        df = pd.read_html(str(soup.find(\"table\",{\"id\":tableId})))[1]\n",
    "    except:\n",
    "        return details\n",
    "    df = remove_columns(df)\n",
    "    for l in df.values:\n",
    "        if len(set([x for x in l if x==x])) == 1:\n",
    "            pre = l[0] +' '\n",
    "            continue\n",
    "        i=1\n",
    "        last_detail = 'abcdef'\n",
    "        while i<len(l):\n",
    "            if l[i-1]==last_detail:\n",
    "                i+=1\n",
    "                continue\n",
    "            details.update({pre+str(l[i-1]):l[i]})\n",
    "            last_detail = l[i]\n",
    "            i+=2\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SURFACE RIGHT GRANT/POSSESSION\n",
    "def get_surface_right_details(link):\n",
    "    linkId = 'SurfaceRightCL'\n",
    "    tableId = 'grdSurface'\n",
    "    pre = ''\n",
    "    details = {}\n",
    "    r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    try:\n",
    "        dfs = pd.read_html(str(soup.find(\"table\",{\"id\":tableId})))\n",
    "    except:\n",
    "        return details\n",
    "    for j in range(1,3):\n",
    "        df = remove_columns(dfs[j])\n",
    "        for l in df.values:\n",
    "            if len(set([x for x in l if x==x])) == 1:\n",
    "                pre = l[0] +' '\n",
    "                continue\n",
    "            i=1\n",
    "            last_detail = 'abcdef'\n",
    "            while i<len(l):\n",
    "                if l[i-1]==last_detail:\n",
    "                    i+=1\n",
    "                    continue\n",
    "                details.update({pre+str(l[i-1]):l[i]})\n",
    "                last_detail = l[i]\n",
    "                if '(HA)' in l[i-1]:\n",
    "                    break\n",
    "                i+=2\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DCC\n",
    "def get_dcc_details(link):\n",
    "    linkId = 'DCC'\n",
    "    tableId = 'grdDCC'\n",
    "    details = {}\n",
    "    r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    try:\n",
    "        df = pd.read_html(str(soup.find(\"table\",{\"id\":tableId})))[0]\n",
    "    except:\n",
    "        return details\n",
    "    for i in df.index:\n",
    "        for c in df.columns:\n",
    "            details.update({c+' '+str(i+1):df[c][i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = 0\n",
    "linkId = 'EnvClearance'\n",
    "tableId = 'grdEnv'\n",
    "if not ml:\n",
    "    tableId = 'rptAccordian_ctl00_tblView'\n",
    "r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "soup = BeautifulSoup(r.content)\n",
    "details = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rptAccordian_ctl00_tblView'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Application Date</th>\n",
       "      <th>Letter No.</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Valid Upto</th>\n",
       "      <th>Mineral Name</th>\n",
       "      <th>Qt. Approved (in MT)</th>\n",
       "      <th>Date of Hearing</th>\n",
       "      <th>View File</th>\n",
       "      <th>Remark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02 Sep 2017</td>\n",
       "      <td>EC/DEIAA/2016-17/26</td>\n",
       "      <td>07 Jan 2018</td>\n",
       "      <td>23 Oct 2022</td>\n",
       "      <td>SAND</td>\n",
       "      <td>102197.0</td>\n",
       "      <td>23 Oct 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as per general condition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Application Date           Letter No.   Order Date   Valid Upto  \\\n",
       "0      02 Sep 2017  EC/DEIAA/2016-17/26  07 Jan 2018  23 Oct 2022   \n",
       "\n",
       "  Mineral Name  Qt. Approved (in MT) Date of Hearing  View File  \\\n",
       "0         SAND              102197.0     23 Oct 2017        NaN   \n",
       "\n",
       "                     Remark  \n",
       "0  as per general condition  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_html(str(soup.find('div',{'class':'viewTable'}).find('table')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = soup.find('div',{\"class\":\"viewTable\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div',{'id':'viewTable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 36\n",
    "link = links['detail_link'][i]\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkId = 'LesseeInfo'\n",
    "tableId = 'grdLeaseInfo'\n",
    "pre = ''\n",
    "details = {}\n",
    "r = requests.get(link.replace('LesseeProfile',linkId))\n",
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"viewTable\">\n",
       "<div>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"div\",{\"class\":\"viewTable\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-1115be5963d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"viewTable\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"table\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m         \u001b[0mdisplayed_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisplayed_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mretained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[0mtables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_tables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcaught\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;31m# if `io` is an io-like object, check if it's seekable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36mparse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparsed\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfooter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mtuples\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \"\"\"\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mtables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_tables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_thead_tbody_tfoot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parse_tables\u001b[1;34m(self, doc, match, attrs)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No tables found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "pd.read_html(str(soup.find(\"div\",{\"class\":\"viewTable\"}).find({\"table\"})))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for l in df.values:\n",
    "    if len(set([x for x in l if x==x])) == 1:\n",
    "        pre = l[0] +' '\n",
    "        continue\n",
    "    i=1\n",
    "    if l[0] == 'Non Forest Area (HA)':\n",
    "        pre = pre+l[0]+' '\n",
    "        i=2\n",
    "    last_detail = 'abcdef'\n",
    "    while i<len(l):\n",
    "        if l[i-1]==last_detail:\n",
    "            i+=1\n",
    "            continue\n",
    "        details.update({pre+str(l[i-1]):l[i]})\n",
    "        last_detail = l[i]\n",
    "        i+=2\n",
    "return details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
